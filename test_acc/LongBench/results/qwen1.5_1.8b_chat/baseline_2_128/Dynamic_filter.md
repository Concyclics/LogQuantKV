对比方法:

H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models（2023 NIPS）

Scissorhands(考虑2023 NIPS)

KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache（考虑 2024ICML） 

MODEL TELLS YOU WHAT TO DISCARD: ADAPTIVE KV CACHE COMPRESSION FOR LLMS（看实验能不能超过 2023NIPS）

NACL: A General and Effective KV Cache Eviction Framework for LLMs at Inference Time （2024 ACL 对比）

KEYFORMER: KV CACHE REDUCTION THROUGH KEY TOKENS SELECTION FOR EFFICIENT GENERATIVE INFERENCE (MLsys)



找2024年ICLR和ICML ACL的文章



逻辑推理问答任务：

gsm8k：



分类任务：

coqa：

openbook：





长文本：

longbench：



文本提取：



问答：

squad:



